\documentclass{article}

\title{STATS 209 - Midterm}
\author{Rene Kizilcec}
\date{Feb 14, 2013}

\begin{document}
\maketitle 
<<setup, include=FALSE, cache=FALSE>>=
opts_chunk$set(fig.path='plots/', fig.align='center', fig.show='asis', echo=TRUE, comment = "", message = FALSE, tidy=FALSE, dev='postscript',fig.width=7, fig.height=5, out.width="\\linewidth")
#options(replace.assign=TRUE,width=60,contrasts=c("contr.sum","contr.poly"))
@


<<echo=FALSE>>=
library(knitr)
library(plyr)
library(ggplot2)
library(psych)
library(lme4)
@

\section*{QUESTION 1}
\subsection*{part a}
Let X1=fitness, X2=stress, X3=illness
<<>>=
r12=-.13
r13=-.29
r23=.34
r13.2=(r13-r12*r23)/((1-r12^2)*(1-r23^2))^.5
r13.2
@
-.264 is not much less than -.29

Obtain CI by converting r to Fisher z' and back.
<<>>=
r.con(-.264,373) 
@
95\% CI does not include 0. No evidence for fitness-illness association to be spurious.

\subsection*{part b}
<<>>=
corPred=matrix(
    c(1,-.03,.39,-.05,-.03,1,.07,-.23,.39,.07,1,-.13,-.05,-.23,-.13,1),
    byrow=F,ncol=4)
corPred
corResp=matrix(c(-.08,-.16,-.29,.34),ncol=1,byrow=F)
coefs = t(corResp)%*%solve(corPred)
coefs 
# same as direct effects in Table 5.2. (kleine p.121)

# compute R-squared (not adjusted)
rsq=coefs%*%corResp
rsq
# covariance matrix with standardized values
covB = as.numeric(1-rsq)*solve(corPred)
covB
# Note that standard errors for standardized coeffs 
# are just square roots of the diagonals adjusted for sample size

# standardized SE for Excercise
sqrt((covB[1,1]/(373))*(373 / (373-4))) 
# standardized SE for Hardiness
sqrt((covB[2,2]/(373))*(373 / (373-4))) 
# standardized SE for Fitness
sqrt((covB[3,3]/(373))*(373 / (373-4))) 
# standardized SE for Stress
sqrt((covB[4,4]/(373))*(373 / (373-4))) 

# c-c' = beta32 * beta13.2 =a*b #where X1=ill,X2=fit,X3=stress
# using Tab 5.2.
mediation=-.11*.29 # = -0.0319
#need to obtain se of fitness, do regression on stress
newCov=cbind(rbind(corPred,t(corResp)),c(corResp,1))
newPred=newCov[-4,-4]
newPred
newResp=t(t(newCov[-4,4]))
newCoefs = t(newResp)%*%solve(newPred)
newRsq=newCoefs%*%newResp
newRsq
# covariance matrix with standardized values
newCov = as.numeric(1-newRsq)*solve(newPred)

# standardized SE for Fitness
sqrt((newCov[3,3]/(373))*(373 / (373-4))) 

# var(c-c')=b^2 Sa^2 + a^2 Sb^2
sobel=(-.11)^2 * 0.05442998 + .29^2 *.048677 
sobel # standardized

@
There mediation effects seems to be rather weak.

\subsection*{part c}
I would expect measurement error to spuriously increase the mediation effect, or even reverse the direction.


\newpage
\section*{QUESTION 2}
\subsection*{part 1}
From the results in Table 3 (use 18-month change from baseline) and Table 5 (use 18-month systolic) estimate the dose-response relation for decrease in systolic blood pressure for each unit decrease in salt intake (as measured by sodium excretion).\\
-43.9 = difference between trt and ctr salt (18 months)\\
-2.06 = difference between trt and ctr blood pressure (18 months)\\
2.06/43.9 = 0.047 reduction in blood pressure for 1 unit reduction in salt intake\\

\emph{What strong assumption did you need to make to justify this estimator?}\\
I assumed a linear dose-response relation (as opposed to a different functional form).\\

\emph{Briefly justify that assumption for this study?}
<<>>=
2.03/((154.6-103)-(156.4-159.3))    # (6months)
1.9/((154.6-100.2)-(156.4-152.1))   # (12months)
2.06/((154.6-99.4)-(156.4-146.5))   # (18months)
@
The doese-response relation measured after 6 and 12 months are very similar, which points at a linear functional form.\\
However, after 18 months, the relation becomes stronger. Note (!) that there is a mistake in Table 3, the "18-Month change from baseline" value for Control, does not correspond to thte difference between Baseline and 18-Month.


\subsection*{part 2}
<<>>=
#install.packages("mediation")
library(mediation)
data(framing)
table(framing$treat) # yes, corresponds
dim(framing) # and yes, also corresponds
@
Let us look at plots of these variables to see what might be going on. It looks like emotional stability is higher for those in the treatment condition (0=ctr, 1=trt) and even more so for those who decide to send a message (0=NotSend, 1=Send).
<<fig=T>>=
par(mfrow=c(1,2))
boxplot(framing$emo~framing$treat, main="Emo for control/treatment")
boxplot(framing$emo~framing$cong_mesg, main="Emo for NotSend/Send")
@
\emph{Is there a significant effect of treatment on emo?}
<<>>=
summary(lm(emo ~ treat,framing))
@
Treatment effect significantly reduces anxiety (increases emo) $est=1.48, se=0.38, t=3.89$

\emph{Is there a significant effect of treatment on cong\_mesg?}
<<>>=
summary(lm(cong_mesg ~ treat,framing)) 
@
No, treatment has no significant effect on cong\_mesg, $t=1.62, p=.11$

\emph{Estimate the effect on probability of sending congressional message of a unit change in "emo" (negative feelings).}
<<>>=
summary(lm(cong_mesg ~ emo,framing)) 
@
The prob. of sending message increases by 6.3\% points for each additional unit of emo. Note that at emo=0, the intercept (baseline prob.) is out of bound (below unit interval). This is a result of using OLS instead of logistic regression.\\

\emph{Compare the "path analysis" estimator (see week 3) for the encouragement design with the estimator you used in part 1.}\\
The estimator in part 1 is result of computing two difference-in-difference points and calculating the slope of straight line that passes though both points.
The 'path analysis' estimator is based on two regressions $BP \sim Salt + Group$, and $Salt\sim Group$.\\
However, these regressions reveal that the 'path analysis' coefficients are biased. There is support for a zero relation between treat and cong\_mesg here (like $\tau=0$ in class). Still, even under this assumption, the 'p.a.' estimator is biased, due to individual differences in cong\_mesg.\\

\emph{Why do the needed assumptions in this study seem far less reasonable than for the salt example?}
It seems unlikely that assignment to group (treat) has no effect on cong\_mesg because people are exposed to media stories in both conditions, which likely raises their awareness of current issues either way (ctr and trt) and thereby increase prob. of sending message. (however, this is not supported by the regression above)\\
An important individual difference that in this study is gender, given that changes in "emo" are likely to different between gender. (Females more emotional than males?) 
<<fig=T>>=
boxplot(framing$emo~framing$gender)
@
It doesn't look like there is a gernder difference in emotional stability from this plot.\\

\emph{Repeat these questions just for the females in the study. Find anything different?}
<<>>=
summary(lm(emo ~ treat,subset(framing,gender=="female"))) 
@
Significant and similar to above, 1.16 increase in emo (anxiety reduction) due to treatment.
<<>>=
summary(lm(cong_mesg ~ treat,subset(framing,gender=="female"))) 
@
Not significant (t=0.14), just like above.
<<>>=
summary(lm(cong_mesg ~ emo,subset(framing,gender=="female")))
@
Significant 5.6\% points prob. increase associated with additional unit emo. Similar to above. Not much different compared to above.

\newpage
\section*{QUESTION 3}
<<>>=
#install.packages("mlmRev")
library(mlmRev)
data(Exam)
@
Check if 'schavg' is really the school mean of 'standLRT'. Looks like schavg and mean(standLRT) correspond very well.
<<>>=
ddply(Exam, .(school,schavg), summarize, "mean(standLRT)"=mean(standLRT))
@

\subsection*{part 1 a}
Individual Level Regression
<<>>=
summary(lm(normexam~standLRT, Exam))
@
Aggregate by school and run group level regression
<<>>=
agg=ddply(Exam, .(school,schavg), summarize, normexam=mean(normexam))
summary(lm(normexam~schavg, agg))
@
Compute aggregation bias: difference in individual and group slope coefficient
<<>>=
0.595057-0.883722
@

\subsection*{part 1 b}
Contextual model\\
<<>>=
summary(lm(normexam~standLRT+schavg, Exam))
@
Contextual effect (=0.354017) is the increase in normexam for unit increase in school LRT score "controlling" for indiv. score.

\subsection*{part 2 c}
<<>>=
coed=subset(Exam, type=="Mxd") # extract coed schools
# check schools with id 43 and 47
table(coed[coed$school==47,"sex"]) # only 1 female, not really coed
table(coed[coed$school==43,"sex"]) # only 1 male, not really coed
@


SFYS regression: $outcome \sim sex | school$
<<>>=
regc=lmList(normexam~sex|school, data=coed)
summary(coef(regc)) 
boxplot(coef(regc)) 
@
Males do worse on average by 0.2693. Outlier slope detected in boxplot, but leaving it in. Looks like a significant gender effect.\\

Multilevel (very basic, each school has own inter./slope)\\
Level 1: $normexam_{ij} = a_{0i} + a_{1i} sex_{ij} + e_{ij}$\\
Level 2: $a_{0i} = b_{00} + e_{0i}$\\
          $a_{1i} = b_{10} + e_{1i}$\\
Combined: $normexam_{ij} = b_{00} + b_{10} sex_{ij} + [e_{ij}+e_{0i}+e_{1i}]$\\
<<>>=
lmer(normexam~sex+(sex|school), coed)
@
$b_{00}$ intercept (female score avg): .03311 (slightly above SFYS)\\
$b_{10}$ gender effect -.2614 (se=.04163) for males (similar to SFYS)\\
There is a significant gender gap in normexam.

\subsection*{part 2 d}
\emph{Note: I just saw the correction today (Thu) before class. There was no email about it and I finished the midterm before 2/12. I'm trying to correct the below, but I hope you are mindful that this is a quick fix.}

Here are some plots that help compare gender. The first one shows normexam for male and female and fits a line that goes through the means for each school. A horizontal line would indicate gender balance in normexam. (This also illustrates the problem with schools 47 and 43).\\
The second plot shows these individual lines and we see that these lines show a downwards trend, confirming that males have lower normexam scores.
<<fig=T>>=
library(lattice)
xyplot(normexam ~ sex | school, type=c("p", "r"), 
       index.cond=function(x,y) 
           {coef(lm(y ~ x))[1]}, data=coed)
xyplot(normexam ~ sex , groups=school, type=c("r"), 
       index.cond=function(x,y) {coef(lm(y ~ x))[1]}, 
       data=coed, col = c("black"))
@

Multilevel (intercept/slope depend on intake)\\
Level 1: $normexam_{ij} = a_{0i} + a_{1i} sex_{ij} + e_{ij}$\\
Level 2: $a_{0i} = b_{00} + b_{01} intake_i + e_{0i}$\\
          $a_{1i} = b_{10} + b_{11} intake_i + e_{1i}$\\
Combined: $normexam_{ij} = b_{00} + b_{01} intake_i + b_{10} sex_{ij} + b_{11} intake_i:sex_{ij} + [e_{ij}+e_{0i}+e_{1i}]$
<<>>=
m1=lmer(normexam~sex*schavg+(sex|school), coed)
m1
@
$b_{00}$ intercept (intake=0,sex=F): -0.072\\
$b_{01}$ intake effect on intercept: est=0.909030, t=5 significant\\
$b_{10}$ gender effect/gap (for male): est=0.129313, t=6 significant\\
$b_{11}$ additional intake effect for males: not significant\\

Maybe better model without interaction effect fits better
<<>>=
m2=lmer(normexam~sex+schavg+(sex|school), coed)
anova(m1,m2) # simpler model favored by AIC and BIC
@
Level 1: $normexam_{ij} \sim a_{0i} + a_{1i} sex_{ij} + e_{ij}$\\
Level 2: $a_{0i} = b_{00} + b_{01} intake_i + e_{0i}$\\
          $a_{1i} = b_{10} + e_{1i}$\\
Combined: $normexam_{ij} \sim b_{00} + b_{01} intake_i + b_{10} sex_{ij} + [e_{ij}+e_{0i}+e_{1i}]$
<<>>=
m2
@
$b_{00}$ intercept (intake=0,sex=F): est=-0.07183\\
$b_{01}$ intake effect on intercept: est=0.91113, t=5.6 significant: higher intake associated with higher normalizd examscore\\
$b_{10}$ gender effect/gap (for male): est=0.12926, t=6.1 significant\\

The gender effect (and its significance in the model) is almost the same as before we added intake to the model. This suggests that the gender gap cannot be explained by the difference in intake, even though intake itself stands out as an important predictor in the model.

\end{document}